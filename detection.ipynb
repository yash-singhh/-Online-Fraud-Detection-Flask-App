{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define dataset path\n",
    "DATASET_PATH = r'C:\\\\Users\\\\Dell\\\\Desktop\\\\Frud_detection\\\\onlinefraud.csv'  # Ensure this file exists\n",
    "\n",
    "# Load dataset safely\n",
    "df = None  # Initialize as None\n",
    "\n",
    "if os.path.exists(DATASET_PATH):  # Check if file exists\n",
    "    try:\n",
    "        df = pd.read_csv(DATASET_PATH)\n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error loading dataset:\", str(e))\n",
    "else:\n",
    "    print(f\"‚ùå ERROR: Dataset file not found at {DATASET_PATH}\")\n",
    "\n",
    "# Load trained models\n",
    "try:\n",
    "    xgb_model = pickle.load(open('.C:\\Users\\Dell\\Desktop\\Frud_detection\\xgb.sav', 'rb'))\n",
    "    lr_model = pickle.load(open('./models/lr.sav', 'rb'))\n",
    "    print(\"‚úÖ Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error loading models:\", str(e))\n",
    "\n",
    "# Define important features\n",
    "important_features = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                      'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', \n",
    "                      'nameOrig', 'nameDest']\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_input(data):\n",
    "    try:\n",
    "        categorical_features = ['type', 'nameOrig', 'nameDest']  # Encode these\n",
    "        numeric_features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                            'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud']\n",
    "\n",
    "        # Transform categorical and numeric features\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "        processed_data = pipeline.fit_transform(pd.DataFrame([data], columns=important_features))\n",
    "        return processed_data\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html', features=important_features)\n",
    "\n",
    "# Prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Collect user input\n",
    "        input_data = {feature: request.form[feature] for feature in important_features}\n",
    "\n",
    "        # Convert numeric values\n",
    "        numeric_keys = ['amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                        'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud']\n",
    "        for key in numeric_keys:\n",
    "            input_data[key] = float(input_data[key])\n",
    "\n",
    "        # Debugging logs\n",
    "        print(\"üü¢ Input Data:\", input_data)\n",
    "\n",
    "        # Preprocess input\n",
    "        final_features = preprocess_input(input_data)\n",
    "        print(\"üü¢ Processed Features Shape:\", final_features.shape)\n",
    "\n",
    "        # Make predictions\n",
    "        fraud_prediction = xgb_model.predict(final_features)[0]\n",
    "        fraud_prob = xgb_model.predict_proba(final_features)[0][1]\n",
    "\n",
    "        return render_template('index.html', \n",
    "                               prediction_text=f'Fraud Prediction: {\"Fraud\" if fraud_prediction else \"Not Fraud\"}',\n",
    "                               probability_text=f'Fraud Probability: {fraud_prob:.2f}',\n",
    "                               features=important_features)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# Run Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e9b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6c0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:40:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models loaded successfully!\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define dataset path\n",
    "DATASET_PATH = r'C:\\\\Users\\\\Dell\\\\Desktop\\\\Frud_detection\\\\onlinefraud.csv'  # Ensure this file exists\n",
    "\n",
    "# Load dataset safely\n",
    "df = None  # Initialize as None\n",
    "\n",
    "if os.path.exists(DATASET_PATH):  # Check if file exists\n",
    "    try:\n",
    "        df = pd.read_csv(DATASET_PATH)\n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error loading dataset:\", str(e))\n",
    "else:\n",
    "    print(f\"‚ùå ERROR: Dataset file not found at {DATASET_PATH}\")\n",
    "\n",
    "# Load trained models\n",
    "try:\n",
    "    xgb_model = pickle.load(open('C:\\\\Users\\\\Dell\\\\Desktop\\\\Frud_detection\\\\xgb.sav', 'rb'))\n",
    "    lr_model = pickle.load(open('C:\\\\Users\\\\Dell\\\\Desktop\\\\Frud_detection\\\\lr.sav', 'rb'))\n",
    "\n",
    "    print(\"‚úÖ Models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error loading models:\", str(e))\n",
    "\n",
    "# Define important features\n",
    "important_features = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                      'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', \n",
    "                      'nameOrig', 'nameDest']\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_input(data):\n",
    "    try:\n",
    "        categorical_features = ['type', 'nameOrig', 'nameDest']  # Encode these\n",
    "        numeric_features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                            'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud']\n",
    "\n",
    "        # Transform categorical and numeric features\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "        processed_data = pipeline.fit_transform(pd.DataFrame([data], columns=important_features))\n",
    "        return processed_data\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html', features=important_features)\n",
    "\n",
    "# Prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Collect user input\n",
    "        input_data = {feature: request.form[feature] for feature in important_features}\n",
    "\n",
    "        # Convert numeric values\n",
    "        numeric_keys = ['amount', 'oldbalanceOrg', 'newbalanceOrig', \n",
    "                        'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud']\n",
    "        for key in numeric_keys:\n",
    "            input_data[key] = float(input_data[key])\n",
    "\n",
    "        # Debugging logs\n",
    "        print(\"üü¢ Input Data:\", input_data)\n",
    "\n",
    "        # Preprocess input\n",
    "        final_features = preprocess_input(input_data)\n",
    "        print(\"üü¢ Processed Features Shape:\", final_features.shape)\n",
    "\n",
    "        # Make predictions\n",
    "        fraud_prediction = xgb_model.predict(final_features)[0]\n",
    "        fraud_prob = xgb_model.predict_proba(final_features)[0][1]\n",
    "\n",
    "        return render_template('index.html', \n",
    "                               prediction_text=f'Fraud Prediction: {\"Fraud\" if fraud_prediction else \"Not Fraud\"}',\n",
    "                               probability_text=f'Fraud Probability: {fraud_prob:.2f}',\n",
    "                               features=important_features)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# Run Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59cefa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
